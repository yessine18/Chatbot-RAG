# ğŸ¤– RAG Chatbot - SystÃ¨me de Questions-RÃ©ponses Intelligent

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Flask 3.0](https://img.shields.io/badge/Flask-3.0-green.svg)](https://flask.palletsprojects.com/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-16-blue.svg)](https://www.postgresql.org/)
[![pgvector](https://img.shields.io/badge/pgvector-enabled-orange.svg)](https://github.com/pgvector/pgvector)

Un systÃ¨me de chatbot intelligent utilisant **Retrieval-Augmented Generation (RAG)** avec **pgvector** pour la recherche vectorielle et **Groq LLM** pour la gÃ©nÃ©ration de rÃ©ponses.

---

## ğŸ“‹ Table des matiÃ¨res

- [Vue d'ensemble](#-vue-densemble)
- [Architecture](#-architecture)
- [Technologies utilisÃ©es](#-technologies-utilisÃ©es)
- [Structure du projet](#-structure-du-projet)
- [Installation](#-installation)
- [Configuration](#-configuration)
- [Scripts Python](#-scripts-python)
- [API Flask](#-api-flask)
- [Recherche vectorielle](#-recherche-vectorielle-pgvector)
- [Interface Web](#-interface-web)
- [Utilisation](#-utilisation)
- [DÃ©ploiement](#-dÃ©ploiement)

---

## ğŸ¯ Vue d'ensemble

Ce projet implÃ©mente un **chatbot RAG (Retrieval-Augmented Generation)** capable de rÃ©pondre aux questions sur l'inscription universitaire en se basant sur :
- **41 fichiers `.txt`** : Conversations historiques sur les inscriptions
- **Fichiers PDF** : Documentation officielle (ex: `accueil_ubs.pdf`)

### FonctionnalitÃ©s principales

âœ… **Recherche vectorielle ultra-rapide** avec pgvector  
âœ… **Support multi-formats** : TXT + PDF  
âœ… **Interface web interactive** avec statistiques temps rÃ©el  
âœ… **API REST complÃ¨te** pour intÃ©gration externe  
âœ… **Historique des conversations** avec sources citÃ©es  
âœ… **Gestion multi-encodage** (UTF-8, Latin-1, CP1252)

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Query  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Flask API (app.py)              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  1. Sentence Transformer         â”‚   â”‚
â”‚  â”‚     (all-MiniLM-L6-v2)          â”‚   â”‚
â”‚  â”‚     â†’ Embedding (384 dims)       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL + pgvector Extension       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  2. Cosine Similarity Search     â”‚   â”‚
â”‚  â”‚     embedding <=> query_vector   â”‚   â”‚
â”‚  â”‚     â†’ Top-K documents (sources)  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Groq API (LLM)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  3. Generate Response            â”‚   â”‚
â”‚  â”‚     Model: llama-3.1-8b-instant  â”‚   â”‚
â”‚  â”‚     Context: Top-K sources       â”‚   â”‚
â”‚  â”‚     â†’ Final Answer               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Response to User   â”‚
â”‚  - Answer            â”‚
â”‚  - Sources (cited)   â”‚
â”‚  - Response time     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Technologies utilisÃ©es

### Backend
| Technologie | Version | Usage |
|------------|---------|-------|
| **Python** | 3.9+ | Langage principal |
| **Flask** | 3.0.0 | API REST framework |
| **PostgreSQL** | 16+ | Base de donnÃ©es |
| **pgvector** | Latest | Extension pour recherche vectorielle |
| **psycopg2** | 2.9.11 | Connecteur PostgreSQL |

### Intelligence Artificielle
| ModÃ¨le | Dimensions | Usage |
|--------|-----------|-------|
| **Sentence Transformers** | 384 | GÃ©nÃ©ration d'embeddings (all-MiniLM-L6-v2) |
| **Groq LLM** | - | GÃ©nÃ©ration de rÃ©ponses (llama-3.1-8b-instant) |

### Frontend
| Technologie | Usage |
|------------|-------|
| **HTML5/CSS3** | Interface utilisateur |
| **JavaScript (Vanilla)** | Logique frontend |
| **Chart.js** | Visualisation des statistiques |
| **Marked.js** | Rendu Markdown |
| **Font Awesome** | IcÃ´nes |

### Traitement de documents
| BibliothÃ¨que | Usage |
|-------------|-------|
| **PyPDF2** | Extraction de texte depuis PDF |
| **pandas** | Manipulation de donnÃ©es |
| **numpy** | Calculs numÃ©riques |

---

## ğŸ“ Structure du projet

```
Chatbot-RAG/
â”‚
â”œâ”€â”€ ğŸ“„ app.py                    # Flask API principale (498 lignes)
â”œâ”€â”€ ğŸ“„ requirements.txt          # DÃ©pendances Python
â”œâ”€â”€ ğŸ“„ .env.example              # Template de configuration
â”œâ”€â”€ ğŸ“„ README.md                 # Documentation (ce fichier)
â”‚
â”œâ”€â”€ ğŸ“‚ src/                      # Scripts utilitaires
â”‚   â”œâ”€â”€ create_db.py             # CrÃ©ation DB + import donnÃ©es
â”‚   â”œâ”€â”€ extract_pdf.py           # Extraction PDF â†’ TXT
â”‚   â””â”€â”€ create_database.sql      # Schema SQL (legacy)
â”‚
â”œâ”€â”€ ğŸ“‚ data/                     # DonnÃ©es sources
â”‚   â”œâ”€â”€ *.txt                    # 41 conversations (UTF-8/Latin-1)
â”‚   â””â”€â”€ *.pdf                    # Documents PDF (ex: accueil_ubs.pdf)
â”‚
â”œâ”€â”€ ğŸ“‚ templates/                # Templates HTML
â”‚   â”œâ”€â”€ index.html               # Interface principale
â”‚   â””â”€â”€ test.html                # Page de test API
â”‚
â”œâ”€â”€ ğŸ“‚ static/                   # Assets frontend
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css            # Styles personnalisÃ©s
â”‚   â””â”€â”€ js/
â”‚       â””â”€â”€ app.js               # Logique frontend (493 lignes)
â”‚
â””â”€â”€ ğŸ“‚ notebook/                 # Prototypes Jupyter
    â”œâ”€â”€ prototypage.ipynb        # RAG prototype
    â””â”€â”€ multi_agent_brain_tumor.ipynb  # SystÃ¨me multi-agents (Option C)
```

---

## ğŸš€ Installation

### PrÃ©requis

- **Python 3.9+**
- **PostgreSQL 16+** avec extension **pgvector**
- **Groq API Key** (gratuit sur [console.groq.com](https://console.groq.com))

### Ã‰tape 1 : TÃ©lÃ©charger le projet

```bash
# Si vous avez clonÃ© depuis GitHub
git clone <votre-repo-url>
cd Chatbot-RAG

# Ou naviguez directement vers le dossier du projet
cd "C:\Users\USER\Desktop\ChatBot Rag\Chatbot-RAG"
```

### Ã‰tape 2 : CrÃ©er un environnement virtuel

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

### Ã‰tape 3 : Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### Ã‰tape 4 : Installer pgvector dans PostgreSQL

```sql
-- Se connecter Ã  PostgreSQL en tant que superuser
CREATE EXTENSION IF NOT EXISTS vector;
```

### Ã‰tape 5 : Configurer les variables d'environnement

```bash
# Copier le template
cp .env.example .env

# Ã‰diter .env avec vos valeurs
notepad .env  # Windows
nano .env     # Linux/Mac
```

**Contenu de `.env` :**
```env
DB_HOST=localhost
DB_PORT=5432
DB_USER=postgres
DB_PASSWORD=votre_mot_de_passe
DB_NAME=rag_chatbot

GROQ_API_KEY=votre_clÃ©_groq_ici
```

### Ã‰tape 6 : CrÃ©er la base de donnÃ©es et importer les donnÃ©es

```bash
cd src
python create_db.py
```

**Sortie attendue :**
```
ğŸ§  Loading embedding model...
âœ… Model loaded!
============================================================
ğŸ“Š Found 43 documents:
   - 41 .txt files
   - 2 .pdf files
âœ… Inserted 305 embeddings into database!
```

---

## âš™ï¸ Configuration

### Variables d'environnement (.env)

| Variable | Description | Valeur par dÃ©faut |
|----------|-------------|-------------------|
| `DB_HOST` | HÃ´te PostgreSQL | `localhost` |
| `DB_PORT` | Port PostgreSQL | `5432` |
| `DB_USER` | Utilisateur DB | `postgres` |
| `DB_PASSWORD` | Mot de passe DB | `your_password_here` |
| `DB_NAME` | Nom de la base | `rag_chatbot` |
| `GROQ_API_KEY` | ClÃ© API Groq | **OBLIGATOIRE** |
| `GROQ_MODEL` | ModÃ¨le LLM | `llama-3.1-8b-instant` |
| `EMBEDDING_MODEL` | ModÃ¨le embeddings | `all-MiniLM-L6-v2` |
| `TOP_K` | Nombre de sources | `5` |
| `MAX_TOKENS` | Tokens max rÃ©ponse | `500` |
| `TEMPERATURE` | CrÃ©ativitÃ© LLM | `0.7` |

---

## ğŸ“œ Scripts Python

### 1ï¸âƒ£ `app.py` - API Flask principale

**Lignes de code :** 498  
**RÃ´le :** Serveur Flask avec API REST complÃ¨te

#### Fonctions clÃ©s :

| Fonction | Description | Technologie |
|----------|-------------|-------------|
| `similar_corpus(query, top_k)` | Recherche vectorielle | **pgvector** (cosine similarity) |
| `generate_response(question, sources)` | GÃ©nÃ©ration de rÃ©ponse | **Groq LLM** |
| `parse_postgres_array(pg_array)` | Parse embeddings | Gestion format `[...]` et `{...}` |

#### Endpoints API :

| Endpoint | MÃ©thode | Description | Retour |
|----------|---------|-------------|--------|
| `/` | GET | Page d'accueil | HTML |
| `/test` | GET | Page test API | HTML |
| `/api/chat` | POST | Poser une question | JSON (answer, sources, time) |
| `/api/stats` | GET | Statistiques DB | JSON (records, files, avg_length) |
| `/api/health` | GET | Health check | JSON (status, db, model) |
| `/api/history` | GET | Historique session | JSON (messages[]) |
| `/api/clear-history` | POST | Effacer historique | JSON (success) |
| `/api/semantic-search` | POST | Recherche pure | JSON (results[]) |

#### Architecture de recherche :

```python
# 1. GÃ©nÃ©ration de l'embedding (384 dimensions)
query_embedding = model.encode(question).tolist()

# 2. Recherche pgvector (cosine similarity)
query = """
    SELECT id, corpus, 
           1 - (embedding <=> %s::vector) as similarity
    FROM embeddings
    ORDER BY embedding <=> %s::vector
    LIMIT %s
"""
# OpÃ©rateur <=> : distance cosinus optimisÃ©e par HNSW index

# 3. GÃ©nÃ©ration de rÃ©ponse avec contexte
response = groq_client.chat.completions.create(
    model="llama-3.1-8b-instant",
    messages=[
        {"role": "system", "content": "Tu es un assistant..."},
        {"role": "user", "content": f"Question: {question}\nContext: {sources}"}
    ]
)
```

---

### 2ï¸âƒ£ `src/create_db.py` - CrÃ©ation et peuplement de la base

**RÃ´le :** Initialise PostgreSQL, active pgvector, charge les donnÃ©es

#### Ã‰tapes du script :

```python
1. create_database()
   â”œâ”€â”€ CREATE DATABASE rag_chatbot
   â”œâ”€â”€ CREATE EXTENSION vector
   â”œâ”€â”€ CREATE TABLE embeddings (
   â”‚       id SERIAL PRIMARY KEY,
   â”‚       corpus TEXT,
   â”‚       embedding VECTOR(384),  # â† pgvector type
   â”‚       file_name VARCHAR(255),
   â”‚       file_type VARCHAR(10),
   â”‚       created_at TIMESTAMP
   â”‚   )
   â””â”€â”€ CREATE INDEX USING hnsw (embedding vector_cosine_ops)

2. load_data_from_folder()
   â”œâ”€â”€ Charge .txt (multi-encodage : UTF-8, Latin-1, CP1252)
   â””â”€â”€ Charge .pdf (PyPDF2.PdfReader)

3. Insert embeddings
   â”œâ”€â”€ DÃ©coupe en chunks (500 caractÃ¨res)
   â”œâ”€â”€ GÃ©nÃ¨re embedding pour chaque chunk
   â””â”€â”€ INSERT INTO embeddings (corpus, embedding, file_name, file_type)
```

#### Gestion multi-encodage :

```python
# Essai automatique de plusieurs encodages
for encoding in ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']:
    try:
        with open(txt_file, 'r', encoding=encoding) as f:
            content = f.read()
            break  # Premier encodage qui fonctionne
    except UnicodeDecodeError:
        continue
```

---

### 3ï¸âƒ£ `src/extract_pdf.py` - Extraction de texte PDF

**RÃ´le :** Convertit les PDF en fichiers `.txt`

```python
def extract_text_from_pdf(pdf_path):
    with open(pdf_path, 'rb') as file:
        pdf_reader = PyPDF2.PdfReader(file)
        text_content = []
        
        for page_num in range(len(pdf_reader.pages)):
            page = pdf_reader.pages[page_num]
            text = page.extract_text()
            text_content.append(f"--- Page {page_num + 1} ---\n{text}")
        
        return "\n".join(text_content)
```

**Utilisation :**
```bash
cd src
python extract_pdf.py
```

---

## ğŸ”Œ API Flask

### Exemple de requÃªte `/api/chat`

**Request :**
```bash
curl -X POST http://localhost:5000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Comment valider mon inscription ?",
    "top_k": 5
  }'
```

**Response :**
```json
{
  "status": "success",
  "answer": "Pour valider votre inscription, vous devez...",
  "sources": [
    {
      "id": 1047,
      "text": "h: inscription administrative oui",
      "relevance": 52.8
    },
    {
      "id": 258,
      "text": "h: un souci avec une inscription",
      "relevance": 47.9
    }
  ],
  "sources_count": 2,
  "response_time": 0.76
}
```

### Statistiques `/api/stats`

**Response :**
```json
{
  "status": "success",
  "stats": {
    "total_records": 305,
    "unique_files": 43,
    "avg_length": 187,
    "files_distribution": {
      "TXT": 41,
      "PDF": 2
    }
  }
}
```

---

## ğŸ” Recherche vectorielle (pgvector)

### â“ Pourquoi pgvector au lieu de FLOAT[] ?

| Aspect | pgvector | FLOAT[] classique |
|--------|----------|-------------------|
| **Performance** | âœ… Indexation HNSW/IVFFlat | âŒ Scan sÃ©quentiel complet |
| **ScalabilitÃ©** | âœ… Millions de vecteurs | âŒ Ralentit avec >10k |
| **OpÃ©rateurs** | âœ… `<=>` (cosine), `<->` (L2) | âŒ Calcul manuel en Python |
| **SQL natif** | âœ… `ORDER BY embedding <=> query` | âŒ RequÃªtes complexes |
| **MÃ©moire** | âœ… OptimisÃ© (compression) | âŒ Stockage brut |

### Exemple de requÃªte pgvector :

```sql
-- Recherche des 5 documents les plus similaires
SELECT 
    id, 
    corpus, 
    1 - (embedding <=> '[0.123, -0.456, ...]'::vector) AS similarity
FROM embeddings
ORDER BY embedding <=> '[0.123, -0.456, ...]'::vector
LIMIT 5;
```

### Index HNSW (Hierarchical Navigable Small World)

```sql
CREATE INDEX embeddings_embedding_idx 
ON embeddings 
USING hnsw (embedding vector_cosine_ops);
```

**Avantages :**
- âš¡ Recherche en **O(log N)** au lieu de O(N)
- ğŸ¯ PrÃ©cision : ~95-99% des rÃ©sultats exacts
- ğŸ“ˆ Scalable jusqu'Ã  des millions de vecteurs

---

## ğŸ¨ Interface Web

### Page principale (`/`)

**FonctionnalitÃ©s :**
- ğŸ’¬ **Chat interactif** : Pose de questions avec historique
- ğŸ“Š **Dashboard** : 4 cartes de statistiques
- ğŸ“ˆ **Graphique** : Distribution des fichiers (Chart.js)
- ğŸ” **Recherche sÃ©mantique** : Tab dÃ©diÃ©e
- ğŸ“œ **Historique** : Conversations sauvegardÃ©es en session

**Technologies :**
- HTML5 + CSS3 (Gradient purple-blue)
- JavaScript Vanilla (Fetch API)
- Chart.js (Visualisation)
- Marked.js (Markdown rendering)

### Page de test (`/test`)

Interface simplifiÃ©e pour tester directement les endpoints API.

---

## ğŸ“Š DonnÃ©es et rÃ©sultats

### Base de donnÃ©es actuelle

| MÃ©trique | Valeur |
|----------|--------|
| **Total embeddings** | 305 |
| **Fichiers .txt** | 41 (134 chunks) |
| **Fichiers .pdf** | 2 (171 chunks) |
| **Dimensions** | 384 (all-MiniLM-L6-v2) |
| **Index** | HNSW (cosine similarity) |

### Performance

| OpÃ©ration | Temps moyen |
|-----------|-------------|
| GÃ©nÃ©ration embedding | ~50ms |
| Recherche pgvector (top-5) | ~10ms |
| GÃ©nÃ©ration LLM (Groq) | ~500-800ms |
| **Total (end-to-end)** | **~0.6-1s** |

---

## ğŸš€ Utilisation

### DÃ©marrer le serveur Flask

```bash
python app.py
```

**Sortie :**
```
================================================================================
ğŸš€ RAG CHATBOT FLASK APPLICATION
================================================================================
ğŸ“Š Database: rag_chatbot@localhost
ğŸ¤– Model: llama-3.1-8b-instant
ğŸ§  Embeddings: all-MiniLM-L6-v2
================================================================================

âœ… Starting server on http://127.0.0.1:5000
```

### AccÃ©der Ã  l'interface

- **Interface principale :** http://localhost:5000
- **Test API :** http://localhost:5000/test
- **Health check :** http://localhost:5000/api/health

### Exemples de questions

**Pour les fichiers .txt (inscriptions) :**
- "Comment faire mon inscription administrative ?"
- "Quels documents sont nÃ©cessaires ?"
- "OÃ¹ se trouve le bureau des inscriptions ?"

**Pour le PDF (accueil_ubs.pdf) :**
- "Qu'est-ce que l'UBS ?"
- "Quels sont les services de l'universitÃ© ?"
- "Comment contacter l'accueil ?"

---

## ğŸ“¦ DÃ©ploiement

### Variables d'environnement production

```env
FLASK_ENV=production
FLASK_DEBUG=False
SECRET_KEY=<gÃ©nÃ©rer-une-clÃ©-sÃ©curisÃ©e>
```

### GÃ©nÃ©rer une clÃ© secrÃ¨te :

```python
import secrets
print(secrets.token_hex(32))
```

### HÃ©bergement recommandÃ©

- **Backend :** Heroku, Railway, Render
- **Base de donnÃ©es :** Railway PostgreSQL (pgvector natif), Supabase
- **Frontend :** Vercel, Netlify (si sÃ©parÃ©)

---

## ğŸ“„ Licence

Ce projet est sous licence MIT.

---

## ğŸ› DÃ©pannage

### Erreur : `ModuleNotFoundError: No module named 'psycopg2'`

```bash
pip install psycopg2-binary
```

### Erreur : `extension "vector" does not exist`

```sql
-- En tant que superuser PostgreSQL
CREATE EXTENSION IF NOT EXISTS vector;
```

### Encodage des fichiers .txt

Le script gÃ¨re automatiquement UTF-8, Latin-1, CP1252. Si erreur, convertir manuellement :

```bash
iconv -f ISO-8859-1 -t UTF-8 fichier.txt > fichier_utf8.txt
```

### ClÃ© Groq invalide

VÃ©rifier sur [console.groq.com](https://console.groq.com) que la clÃ© est active.

---

## ğŸ“ Support

Pour toute question ou assistance, consultez la documentation ci-dessus ou vÃ©rifiez les logs de l'application.

---

## Features

- Retrieval-Augmented Generation for enhanced responses
- Context-aware conversations
- Easy-to-use interface

## Getting Started

### Prerequisites

- Python 3.8+
- Required dependencies (to be listed in requirements.txt)

### Installation

```bash
# Clone the repository
git clone git@github.com:yessine18/Chatbot-RAG.git
cd Chatbot-RAG

# Install dependencies
pip install -r requirements.txt
```

### Usage

```bash
# Run the chatbot
python main.py
```

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is licensed under the MIT License.
